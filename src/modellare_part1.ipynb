{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la8I22c9PfMK"
      },
      "source": [
        "# Cosa sono veramente le **Neural Networks**?\n",
        "\n",
        "Nelle prossime due ore (circa) proveremo a **esplorare alcuni aspetti pratici che riguardano le reti neurali**: (i) l'implementazione della struttura della rete e (ii) il meccanismo di addestramento. \n",
        "Per farlo, ci serviremo di un linguaggio di programmazione e di un editor di testo.\n",
        "\n",
        "## Strumenti\n",
        "\n",
        "Prima di tutto, usiamo, come editor di testo, un _Google Colaboratory Notebook_ (se non sai cos'è un notebook puoi [dare un occhio qui](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html)).\n",
        "In breve, questo strumento ci permette di scrivere testo formattato e codice in un unico file e di eseguirlo in un ambiente online (pronto all'uso).\n",
        "\n",
        "## Prerequisiti \n",
        "\n",
        "Il tutorial assume la conoscenza dei seguenti concetti basilari: \n",
        "- **operazioni tra tensori** (vettori multidimensionali) che sono solitamente oggetto di un corso base di algebra lineare, \n",
        "- qualche nozione di **teoria delle probabilità**,\n",
        "- **un po' di Python** o di un linguaggio ad oggetti similare."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9PWoJN01HMO"
      },
      "source": [
        "# Cominciamo con un po' di storia\n",
        "\n",
        "Come sicuramente il lettore saprà, il padre del _perceptron_, l'algoritmo alla base di tutte le reti neurali, è **Frank Rosenblatt**, vissuto tra il 1928 e il 1971.\n",
        "Frank riprende il lavoro di due colleghi, Warren McCulloch e Walter Pitts, che intorno al 1943 studiano le analogie tra il meccanismo di attivazione delle cellule neuronali e l'output delle porte logiche.\n",
        "\n",
        "> L'intuizione è che il segnale (input) si accumula nel neurone fino al raggiungimento di una soglia critica. Se questa soglia viene superata allora il neurone si attiva ed emette un segnale in uscita (output).\n",
        "\n",
        "Rosenblatt immagina un modo di apprendere quando un neurone si attiva, così da poter costrure un classificatore lineare binario, in grado di separare linearmente dei segnali tra due classi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfszdZoIG5_e"
      },
      "source": [
        "Un po' più formalmente, il percettrone corrisponde ad un modello per l'aggiornamento dei pesi $w$ associati ad un vettore di input $x$ (la rappresentazione del segnale). L'input ed i relativi pesi si \"accumulano\" nel percettrone, la quantità risultante viene processata da una **funzione di attivazione** che produce l'output (la classe della predizione).\n",
        "\n",
        "Il primo valore dell'input $x_0=1$ ed il suo peso $w_0$ prendono il nome di **bias**, un valore che regolarizza l'output dell'algoritmo ed evita problemi di _overfitting_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixhEjFQ0Iuxd"
      },
      "source": [
        "Infine, la forma del percettrone così come è stato ideato da Rosenblatt:\n",
        "\n",
        "$$\n",
        "\\hat y = f( \\sum_{i=1} x_i w_i + \\textit{bias})\n",
        "$$\n",
        "\n",
        "Si noti che $x_0*w_0$ è separato dalla sommatoria e chiamato $\\textit{bias}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_itZcfE-X-2w"
      },
      "source": [
        "# L'algoritmo di Rosenblatt\n",
        "\n",
        "L'algoritmo, nella sua semplicità, prevede i seguenti passaggi:\n",
        "1. Inizializzo il vettore dei pesi $w$ con valori _opportuni_\n",
        "2. Per ogni input $x$\n",
        "  - Calcolo il valore dell'output $\\hat y$ con la funzione di attivazione\n",
        "  - Aggiorno il vettore dei pesi $w$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txGZ2vGaX4sg"
      },
      "source": [
        "## La funzione di attivazione $f$\n",
        "\n",
        "Concentriamoci sul calcolo del valore $\\hat y$, prima di tutto abbiamo bisogno di definire la funzione di attivazione.\n",
        "\n",
        "Nonostante la varietà di funzioni possibili, la prima funzione di attivazione pensata da Rosenblatt è molto semplice:\n",
        "se il segno del valore di accumulo è positivo allora l'output è 1, -1 altrimenti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKQJJ23II8po"
      },
      "outputs": [],
      "source": [
        "def sign(n):\n",
        "  if n>0:\n",
        "    return 1\n",
        "  else:\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh8w7boaHtTY"
      },
      "outputs": [],
      "source": [
        "def relu(n):\n",
        "  if n<0:\n",
        "    return 0\n",
        "  else:\n",
        "    return n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7A_Ke4xHyYy",
        "outputId": "f6e5e82b-1003-4bef-f2ed-1da3d1392636"
      },
      "outputs": [],
      "source": [
        "relu(-10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPlzcbFRLdEc",
        "outputId": "5c323e89-9285-4563-88b0-d74d0d9fd4ac"
      },
      "outputs": [],
      "source": [
        "sign(-.000000000009)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RWjzYcHXRPG"
      },
      "source": [
        "Possiamo adesso scrivere l'algoritmo _semplificato_ per il percettrone di Rosenblatt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-I6SEe6I9U9"
      },
      "outputs": [],
      "source": [
        "def perceptron(x, w, bias, f=sign):\n",
        "  sigma = 0\n",
        "  for i in range(len(x)):\n",
        "    sigma += x[i] * w[i]\n",
        "  sigma += bias \n",
        "  return f(sigma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fknC6EEUaDNr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def np_perceptron(x, w, bias, f=sign):\n",
        "  return f(np.sum(np.dot(x, w)) + bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDwtGnAUXYxd"
      },
      "source": [
        "Testiamo il nostro codice con un semplice input formato da due variabili: il punto di coordinate 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzE96UCpI9z4"
      },
      "outputs": [],
      "source": [
        "# dichiaro l'input del percettrone\n",
        "x = [0,1]\n",
        "\n",
        "import random\n",
        "# inizializzo una casualmente la lista di pesi \n",
        "w = [random.uniform(-1,1) for i in range(len(x))]\n",
        "# inizializza casualmente il bias\n",
        "bias = random.uniform(-1,1)\n",
        "\n",
        "# assegno la funzione di attivazione (in questo caso ReLU)\n",
        "f = relu\n",
        "\n",
        "# calcolo il valore output del precettrone\n",
        "y_pred = perceptron(x, w, bias, relu) # try np_perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-xTQPQdOqlV",
        "outputId": "add7f343-1d66-4da4-a089-832c7df59a2a"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u809FhzhV3Ur"
      },
      "source": [
        "Il lettore avrà notato che attualmente non abbiamo una strategia di aggiornamento dei pesi, il nostro modello infatti non sta veramente apprendendo, sta soltanto calcolando l'output.\n",
        "\n",
        "Per farlo dobbiamo **calcolare l'errore commesso dal classificatore** e aggiornare i pesi tenendo in considerazione la differenza (se presente) tra la classe reale e la predizione. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8x_3DLyPFv-"
      },
      "source": [
        "## L'addestramento (o aggiornamento dei pesi)\n",
        "\n",
        "L'aggiornamento del vettore dei pesi $w$ deve essere fatto per ogni peso $w_i$, in generale vogliamo modificare la quantità $w_i$ di un certo $\\Delta y_i$.\n",
        "\n",
        "$$\n",
        "w_i = w_i + \\Delta y_i\n",
        "$$\n",
        "\n",
        "Il $\\Delta y_i$ rappresenta la differenza tra il valore reale (*ground truth*) e la predizione, in altre parole l'**errore** del percettrone.\n",
        "\n",
        "$$\n",
        "\\Delta y = \\hat{y} - y\n",
        "$$\n",
        "\n",
        "Nel processo di addestramento introduciamo una nuova variabile: il **learning rate** (abbreviato con `lr`), un fattore di moltiplicazione \"piccolo\" a piacere, che permettere di *regolare* l'aggiornamento dei pesi.\n",
        "\n",
        "Il suo ruolo è quello di ridurre il valore con cui aggiorniamo i pesi della rete, per non \"esagerare\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj_AZ1xPJAfg"
      },
      "outputs": [],
      "source": [
        "def train_perceptron(x, w, bias, y, lr=0.1, f=sign):\n",
        "  # calcoliamo la predizione\n",
        "  y_pred = perceptron(x, w, bias, f)\n",
        "  # calcoliamo la differenza tra la predizione e la realtà\n",
        "  errore = y - y_pred\n",
        "  # aggiorniamo i pesi e il bias\n",
        "  bias += errore\n",
        "  for i in range(len(w)):\n",
        "    w[i] += lr * errore * x[i]\n",
        "  return w, bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHMAZDCbeTbB"
      },
      "source": [
        "# Mettiamo tutto insieme in un esempio\n",
        "\n",
        "Supponiamo di voler creare un percettrone in grado di imparare il comportamento della porta logica `AND`.\n",
        "\n",
        "Il dataset di train sara composto dalle coppie di valori booleani $p$ e $q$ mentre la classe associata ad ogni coppia (il valore _target_) corrisponde all'operazione $p \\land q$.\n",
        "\n",
        "|p|q|p $\\land$ q|\n",
        "|:-:|:-:|:---------:|\n",
        "|0|0|0|\n",
        "|0|1|0|\n",
        "|1|0|0|\n",
        "|1|1|1|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VypG1OqhH2qc"
      },
      "source": [
        "Definiamo il dataset di addestramento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5M-FLicbJCc5"
      },
      "outputs": [],
      "source": [
        "x_train = [[1,0],\n",
        "           [0,0],\n",
        "           [1,1],\n",
        "           [0,0]]\n",
        "y_train = [1,1,1,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iTKcwmzH6Qv"
      },
      "source": [
        "Inizializziamo i valori del vettore dei pesi in modo pseudo-random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_tv3fJUIlXQ",
        "outputId": "c1f81272-330f-4564-85b5-00d7b2fb78cc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# inizializzo una casualmente la lista di pesi \n",
        "w = [random.uniform(-1,1) for i in range(len(x))]\n",
        "# inizializza casualmente il bias\n",
        "bias = random.uniform(-1,1)\n",
        "w, bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ju7AtFtI1Ig"
      },
      "source": [
        "Addestriamo il modello per ogni valore dell'input del **train dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoXJ1nXZIxOg",
        "outputId": "4acbcb97-834c-442a-b1c5-a1ed9431ddcf"
      },
      "outputs": [],
      "source": [
        "def train_once(x_train, y_train, w, bias):\n",
        "  for i in range(len(x_train)):\n",
        "    w, bias = train_perceptron(x_train[i], w, bias, y_train[i], f=sign)\n",
        "  return w, bias\n",
        "\n",
        "train_once(x_train, y_train, w, bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjweaunTI9M3"
      },
      "source": [
        "Facciamo un **test** del modello sui dati in **train** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4kBoAd-I9gs",
        "outputId": "db6afe76-cd02-4045-8927-9d88e80a7599"
      },
      "outputs": [],
      "source": [
        "for x in x_train:\n",
        "  print(x, perceptron(x, w, bias))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tE1vCaHI9xu"
      },
      "source": [
        "Addestriamo per un numero arbitrario di \"giri\" dell'input (diciamo 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEoxFxgXI-Gd",
        "outputId": "bbcb11f6-7be6-4164-c062-41e76c138f71"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "def train_epochs(x_train, y_train, w, bias, epochs):\n",
        "  for _ in range(epochs):\n",
        "    print(w, bias)\n",
        "    w, bias = train_once(x_train, y_train, w, bias)\n",
        "\n",
        "train_epochs(x_train, y_train, w, bias, epochs)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30kwV8F6JkED",
        "outputId": "e061e9f6-21ff-4713-dc2e-d457a3710ee1"
      },
      "outputs": [],
      "source": [
        "for x in x_train:\n",
        "  print(x, perceptron(x, w, bias))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1BKPEwJSW1"
      },
      "source": [
        "# Grazie per la vostra attenzione :-)\n",
        "\n",
        "Sono a disposizione per chiarimenti e discussioni, anche per eventuali idee di progetto sulle Reti Neurali. \n",
        "\n",
        "Mi potete contattare alla mail istituzionali [stefanopio \\[dot\\] zingaro \\[at\\] unibo \\[dot\\] it](mailto:stefanopio.zingaro@unibo.it)\n",
        "\n",
        "Quest'opera è distribuita con Licenza Creative Commons Attribuzione - Condividi allo stesso modo 4.0 Internazionale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ2gPOZVgzhm"
      },
      "source": [
        "# Ringraziamenti\n",
        "\n",
        "* [Maurizio Gabbrielli](https://www.unibo.it/sitoweb/maurizio.gabbrielli) per aver accolto la mia volontà di efettuare la lezione in questa modalità `python-notebook`.\n",
        "* [Simone Martini](https://www.cs.unibo.it/~martini/) e [Marco Sbaraglia](https://www.unibo.it/sitoweb/marco.sbaraglia/), i quali hanno enormemente contribuito al miglioramento di questa \"lezione\". "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "percettrone.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
